# Adversarial

## Tools
* robust bench: https://robustbench.github.io/
* fool box: https://foolbox.readthedocs.io/en/stable/index.html
* AdverTorch: https://github.com/BorealisAI/advertorch

## benchmarks
* robust-ml: https://www.robust-ml.org/
* robust bench: https://robustbench.github.io/
* 

## Paper
* auto-attack: https://arxiv.org/pdf/2003.01690.pdf
* WILDS: Distribution shifts: https://arxiv.org/pdf/2012.07421v1.pdf
*
### adaptive attacks: 
* https://arxiv.org/pdf/2002.08347.pdf 
* https://arxiv.org/pdf/2002.08347.pdf

* 
